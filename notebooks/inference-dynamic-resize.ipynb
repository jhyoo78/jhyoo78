{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhyoo78/jhyoo78/blob/main/notebooks/inference-dynamic-resize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wxgb-sWfpb49"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "This notebook shows how to run inference with the [MAXIM family of models](https://github.com/google-research/maxim) from [TensorFlow Hub](https://tfhub.dev/sayakpaul/collections/maxim/1). MAXIM family of models share the same backbone for performing: denoising, dehazing, deblurring, deraining, and enhancement. You can know more about the public MAXIM models from [here](https://github.com/google-research/maxim#results-and-pre-trained-models).\n",
        "\n",
        "This notebook allows you to run dynamic shaped images unlike [this one](https://github.com/sayakpaul/maxim-tf/blob/main/notebooks/inference.ipynb)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zlp7twW3tB2n"
      },
      "source": [
        "## Select a checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "E-n8jA4Gojv2",
        "outputId": "c163ca3f-c7b3-48b7-a22e-312b6b14ac5a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF-Hub handle: https://tfhub.dev/sayakpaul/maxim_s-2_enhancement_lol/1.\n"
          ]
        }
      ],
      "source": [
        "task = \"Enhancement\"  # @param [\"Denoising\", \"Dehazing_Indoor\", \"Dehazing_Outdoor\", \"Deblurring\", \"Deraining\", \"Enhancement\", \"Retouching\"]\n",
        "\n",
        "model_handle_map = {\n",
        "    \"Denoising\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-3_denoising_sidd/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Denoising/input/0003_30.png\",\n",
        "    ],\n",
        "    \"Dehazing_Indoor\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_dehazing_sots-indoor/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Dehazing/input/0003_0.8_0.2.png\",\n",
        "    ],\n",
        "    \"Dehazing_Outdoor\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_dehazing_sots-outdoor/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Dehazing/input/1444_10.png\",\n",
        "    ],\n",
        "    \"Deblurring\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-3_deblurring_gopro/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Deblurring/input/1fromGOPR0950.png\",\n",
        "    ],\n",
        "    \"Deraining\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_deraining_raindrop/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Deraining/input/15.png\",\n",
        "    ],\n",
        "    \"Enhancement\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_enhancement_lol/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Enhancement/input/a4541-DSC_0040-2.png\",\n",
        "    ],\n",
        "    \"Retouching\": [\n",
        "        \"https://tfhub.dev/sayakpaul/maxim_s-2_enhancement_fivek/1\",\n",
        "        \"https://github.com/google-research/maxim/raw/main/maxim/images/Enhancement/input/a4541-DSC_0040-2.png\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "model_handle = model_handle_map[task]\n",
        "ckpt = model_handle[0]\n",
        "print(f\"TF-Hub handle: {ckpt}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3t6c3Z1Pz6UT"
      },
      "source": [
        "For deblurring, there are other checkpoints too:\n",
        "\n",
        "- https://tfhub.dev/sayakpaul/maxim_s-3_deblurring_realblur_r/1\n",
        "- https://tfhub.dev/sayakpaul/maxim_s-3_deblurring_realblur_j/1\n",
        "- https://tfhub.dev/sayakpaul/maxim_s-3_deblurring_reds/1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SNlQ2HzrtJOU"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "IEhpgokqtKFz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# MAXIM git code 설치\n",
        "\n",
        "#!pip install git+https://github.com/google-research/maxim\n",
        "\n",
        "!git clone https://github.com/sayakpaul/maxim-tf.git/    #Python project가 아니라서 pipㅇ로 설치 불가\n",
        "!python3 /content/maxim-tf/create_maxim_model.py   # Model() 정의\n",
        "!python3 /content/maxim-tf/maxim/configs.py        # MAXIM_CONFIGS 정의됨"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RnzLuSz5pKLD",
        "outputId": "37fc5e76-bcae-42f1-e870-f4835dcd50fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'maxim-tf' already exists and is not an empty directory.\n",
            "2025-02-14 15:04:46.563728: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1739545486.587231    5688 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1739545486.594029    5688 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "us19UdxvdE18",
        "outputId": "d242c40e-1a0f-4b07-ec5b-6d7b3a36f7a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 516
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "cannot import name 'maxim' from 'maxim' (/usr/local/lib/python3.11/dist-packages/maxim/__init__.py)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-de43bdb0baa0>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaxim_tf_path\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#--> 추가\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mcreate_maxim_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m       \u001b[0;31m#  https://github.com/sayakpaul/maxim-tf/tree/main 에 있음\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaxim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAXIM_CONFIGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/maxim-tf/create_maxim_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmaxim\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmaxim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmaxim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfigs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMAXIM_CONFIGS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'maxim' from 'maxim' (/usr/local/lib/python3.11/dist-packages/maxim/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "#sys.path.append(\"..\") # --> 디렉토리 문제 인 듯...\n",
        "\n",
        "# Get the absolute path to the directory containing create_maxim_model.py\n",
        "# Assuming maxim-tf is in the same directory as your notebook\n",
        "maxim_tf_path = os.path.join(os.getcwd(), 'maxim-tf') # --> 추가\n",
        "\n",
        "# Add the directory to the Python path\n",
        "sys.path.append(maxim_tf_path)  #--> 추가\n",
        "\n",
        "from create_maxim_model import Model       #  https://github.com/sayakpaul/maxim-tf/tree/main 에 있음\n",
        "from maxim.configs import MAXIM_CONFIGS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEtzvxy5dE18"
      },
      "source": [
        "TODO: When the repository is public, clone it and use accordingly."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTdrCvUltkCn"
      },
      "source": [
        "## Fetch the input image based on the task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bn90H1rltRcM"
      },
      "outputs": [],
      "source": [
        "image_url = model_handle[1]\n",
        "image_path = tf.keras.utils.get_file(origin=image_url)\n",
        "Image.open(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qs1FCtINdE19"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7dzkVpOQdE1-"
      },
      "outputs": [],
      "source": [
        "_MODEL = tf.keras.models.load_model(ckpt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UsXRY1kvum4O"
      },
      "source": [
        "## Preprocessing utilities\n",
        "\n",
        "Based on [this official script](https://github.com/google-research/maxim/blob/main/maxim/run_eval.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZGmgEtfLt7S5"
      },
      "outputs": [],
      "source": [
        "def mod_padding_symmetric(image, factor=64):\n",
        "    \"\"\"Padding the image to be divided by factor.\"\"\"\n",
        "    height, width = image.shape[0], image.shape[1]\n",
        "    height_pad, width_pad = ((height + factor) // factor) * factor, (\n",
        "        (width + factor) // factor\n",
        "    ) * factor\n",
        "    padh = height_pad - height if height % factor != 0 else 0\n",
        "    padw = width_pad - width if width % factor != 0 else 0\n",
        "    image = tf.pad(\n",
        "        image, [(padh // 2, padh // 2), (padw // 2, padw // 2), (0, 0)], mode=\"REFLECT\"\n",
        "    )\n",
        "    return image\n",
        "\n",
        "\n",
        "def make_shape_even(image):\n",
        "    \"\"\"Pad the image to have even shapes.\"\"\"\n",
        "    height, width = image.shape[0], image.shape[1]\n",
        "    padh = 1 if height % 2 != 0 else 0\n",
        "    padw = 1 if width % 2 != 0 else 0\n",
        "    image = tf.pad(image, [(0, padh), (0, padw), (0, 0)], mode=\"REFLECT\")\n",
        "    return image\n",
        "\n",
        "\n",
        "def process_image(image: Image):\n",
        "    input_img = np.asarray(image) / 255.0\n",
        "    height, width = input_img.shape[0], input_img.shape[1]\n",
        "\n",
        "    # Padding images to have even shapes\n",
        "    input_img = make_shape_even(input_img)\n",
        "    height_even, width_even = input_img.shape[0], input_img.shape[1]\n",
        "\n",
        "    # padding images to be multiplies of 64\n",
        "    input_img = mod_padding_symmetric(input_img, factor=64)\n",
        "    input_img = tf.expand_dims(input_img, axis=0)\n",
        "    return input_img, height, width, height_even, width_even\n",
        "\n",
        "\n",
        "def init_new_model(input_img):\n",
        "    variant = ckpt.split(\"/\")[-1].split(\"_\")[0]\n",
        "    configs = MAXIM_CONFIGS.get(variant)\n",
        "    configs.update(\n",
        "        {\n",
        "            \"variant\": \"S-2\",\n",
        "            \"dropout_rate\": 0.0,\n",
        "            \"num_outputs\": 3,\n",
        "            \"use_bias\": True,\n",
        "            \"num_supervision_scales\": 3,\n",
        "        }\n",
        "    )  # From https://github.com/google-research/maxim/blob/main/maxim/run_eval.py#L45-#L61\n",
        "    configs.update({\"input_resolution\": (input_img.shape[1], input_img.shape[2])})\n",
        "    new_model = Model(**configs)\n",
        "    new_model.set_weights(_MODEL.get_weights())\n",
        "    return new_model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVOdyjTudE1_"
      },
      "source": [
        "To make the model operate on images of arbitrary shapes here's what we're doing:\n",
        "\n",
        "* Loading the initial pre-trained model into `_MODEL`.\n",
        "* Initializing a separate instance of MAXIM based on the configs and spatial resolutions of the input image.\n",
        "* Populating the params of this newly initialized model with that of `_MODEL`.\n",
        "\n",
        "All of it is handled in `init_new_model()`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5T20A1xLvcLq"
      },
      "source": [
        "## Run predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hOxESHl2vdRE"
      },
      "outputs": [],
      "source": [
        "# Based on https://github.com/google-research/maxim/blob/main/maxim/run_eval.py\n",
        "def infer(image_path: str):\n",
        "    image = Image.open(image_path).convert(\"RGB\")\n",
        "    preprocessed_image, height, width, height_even, width_even = process_image(image)\n",
        "    new_model = init_new_model(preprocessed_image)\n",
        "\n",
        "    preds = new_model.predict(preprocessed_image)\n",
        "    if isinstance(preds, list):\n",
        "        preds = preds[-1]\n",
        "        if isinstance(preds, list):\n",
        "            preds = preds[-1]\n",
        "\n",
        "    preds = np.array(preds[0], np.float32)\n",
        "\n",
        "    new_height, new_width = preds.shape[0], preds.shape[1]\n",
        "    h_start = new_height // 2 - height_even // 2\n",
        "    h_end = h_start + height\n",
        "    w_start = new_width // 2 - width_even // 2\n",
        "    w_end = w_start + width\n",
        "    preds = preds[h_start:h_end, w_start:w_end, :]\n",
        "\n",
        "    return np.array(np.clip(preds, 0.0, 1.0))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Fr-rYLpwab6"
      },
      "outputs": [],
      "source": [
        "final_pred_image = infer(image_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTq1J42tw67G"
      },
      "source": [
        "## Visualize results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECGdFWQBw8E2"
      },
      "outputs": [],
      "source": [
        "# Based on https://www.tensorflow.org/lite/examples/style_transfer/overview#visualize_the_inputs\n",
        "def imshow(image, title=None):\n",
        "    if len(image.shape) > 3:\n",
        "        image = tf.squeeze(image, axis=0)\n",
        "\n",
        "    plt.imshow(image)\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "\n",
        "\n",
        "plt.figure(figsize=(15, 15))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "input_image = np.asarray(Image.open(image_path).convert(\"RGB\"), np.float32) / 255.0\n",
        "imshow(input_image, \"Input Image\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "imshow(final_pred_image, \"Predicted Image\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}