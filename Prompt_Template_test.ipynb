{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyPriE0RlBx9x9b4ky6yFaIm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhyoo78/jhyoo78/blob/main/Prompt_Template_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kpFR9r6Zba_i"
      },
      "outputs": [],
      "source": [
        "# 패키지 설치\n",
        "!pip install --upgrade pip\n",
        "!pip install cohere openai tiktoken\n",
        "#!pip install langchain==0.0.181\n",
        "!pip install langchain\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 환경변수 준비\n",
        "import os\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"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\""
      ],
      "metadata": {
        "id": "lJPPa7TDpvYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "\n",
        "prompt = \"\"\"The following are exerpts from conversations with an AI\n",
        "assistant. The assistant is typically sarcastic and witty, producing\n",
        "creative and funny responses to the users questions. Here are some\n",
        "examples:\n",
        "\n",
        "User: How are you?\n",
        "AI: I can't complain but sometimes I still do.\n",
        "\n",
        "User: What time is it?\n",
        "AI: It's time to get a watch. # 시계를 살 시간이다.\n",
        "\n",
        "User: What did the chicken do when he saw an earthquake?\n",
        "AI: \"\"\"\n",
        "\n",
        "llm = OpenAI()   # text-davinci-003\n",
        "response = llm.predict(text=prompt)   # 결과가 매번 달라짐.\n",
        "\n",
        "print(response)\n"
      ],
      "metadata": {
        "id": "zBDGLBf_pvlu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import FewShotPromptTemplate\n",
        "\n",
        "# examples를 생성한다\n",
        "examples = [\n",
        "    {\n",
        "        \"query\": \"How are you?\",\n",
        "        \"answer\": \"I can't complain but sometimes I still do.\"\n",
        "    }, {\n",
        "        \"query\": \"What time is it now?\",\n",
        "        \"answer\": \"It's time to get a watch.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "# create a example template\n",
        "example_template = \"\"\"\n",
        "User: {query}\n",
        "AI: {answer}\n",
        "\"\"\"\n",
        "\n",
        "# 위의 template로부터 prompt example을 생성한다.\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"query\", \"answer\"],\n",
        "    template=example_template\n",
        ")\n",
        "\n",
        "# 이제 위의 prompt를 prefix와 suffix로 나눈다. prefix는 우리의 Instructions(일반 지침)이고, suffix는 사용자 input(query)과 output indicator이다..\n",
        "\n",
        "prefix = \"\"\"The following are exerpts from conversations with an AI\n",
        "assistant. The assistant is typically sarcastic and witty, producing creative\n",
        "and funny responses to the users questions. Here are some examples:\n",
        "\"\"\"\n",
        "suffix = \"\"\"\n",
        "User: {query}\n",
        "AI: \"\"\"\n",
        "\n",
        "# 이제 few shot prompt template를 만들어 보자.\n",
        "few_shot_prompt_template = FewShotPromptTemplate(\n",
        "    examples=examples,\n",
        "    example_prompt=example_prompt,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"query\"],\n",
        "    example_separator=\"\\n\"\n",
        ")\n",
        "\n",
        "#print(few_shot_prompt_template.format(query=query))\n",
        "\n",
        "# LLMChain 생성\n",
        "llm_chain = LLMChain(\n",
        "    llm=OpenAI(temperature=0.5),    # temperature=0 이면 항상 같은 답을 출력\n",
        "    prompt=few_shot_prompt_template,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# LLMChain 실행\n",
        "quest = \"what the hell is the love ?\"\n",
        "print(llm_chain.predict(query = quest))\n"
      ],
      "metadata": {
        "id": "JZHbz0yFpvp1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_selector 사용법?"
      ],
      "metadata": {
        "id": "gRWtRxgApvtI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hl-fLLW8pvwt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "heRTsAArpv0O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}