{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMxAz/1ansRUYSY/eRKttit",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhyoo78/jhyoo78/blob/main/Senticnet_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkp8rIQQ1bIg"
      },
      "outputs": [],
      "source": [
        "!pip install senticnet"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from senticnet.senticnet import SenticNet\n",
        "\n",
        "sn = SenticNet()\n",
        "concept_info = sn.concept('long')     # senticnet에 없는 단어는 오류\n",
        "print(concept_info)"
      ],
      "metadata": {
        "id": "5hCt4gPx1e1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "polarity_label = sn.polarity_label('cold')   # 감정을 포함하는 단어(형용사)만 다루는 듯\n",
        "polarity_value = sn.polarity_value('low')\n",
        "moodtags = sn.moodtags('love')\n",
        "semantics = sn.semantics('love')\n",
        "sentics = sn.sentics('love')"
      ],
      "metadata": {
        "id": "EhXII0wS3bEc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(concept_info)\n",
        "print()\n",
        "print(sentics)\n"
      ],
      "metadata": {
        "id": "di3D9P6s2aXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from senticnet.babelsenticnet import BabelSenticNet\n",
        "\n",
        "bsn = BabelSenticNet('pt')\n",
        "concept_info = bsn.concept('amor')\n",
        "polarity_label = bsn.polarity_label('amor')\n",
        "polarity_value = bsn.polarity_value('amor')\n",
        "moodtags = bsn.moodtags('amor')\n",
        "semantics = bsn.semantics('amor')\n",
        "sentics = bsn.sentics('amor')"
      ],
      "metadata": {
        "id": "hEry75H53fzT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(concept_info)\n",
        "print()\n",
        "print(sentics)"
      ],
      "metadata": {
        "id": "pQk1s-d23f0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install senticnet"
      ],
      "metadata": {
        "id": "MrGlH-UrLQlz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from senticnet.senticnet import SenticNet\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# define sentinet()\n",
        "sn = SenticNet()\n",
        "\n",
        "# create empty list to store results\n",
        "emotion_list = []\n",
        "\n",
        "# 텍스트 토큰화하기\n",
        "# you can use word_tokenize() from the nltk library to tokenize your text\n",
        "text = 'love hate python'\n",
        "#text = 'started'     # I start long 등의 단어는 오류 발생시킴\n",
        "tokenized_text = word_tokenize(text)\n",
        "\n",
        "# loop through tokenized text and emtion and append to list\n",
        "for word in tokenized_text:\n",
        "    emotion_list.append(sn.polarity_value(word))\n",
        "# print\n",
        "print(emotion_list)"
      ],
      "metadata": {
        "id": "q9ACWC-WK5dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def emotion_data(comment):\n",
        "    comment = comment.translate({ord(c): '' for c in string.punctuation})\n",
        "    sn = Senticnet()\n",
        "    polarity_intense = 0\n",
        "    comment_sentics = {\n",
        "        'sensitivity': 0,\n",
        "        'attention': 0,\n",
        "        'pleasantness': 0,\n",
        "        'aptitude': 0\n",
        "    }\n",
        "    comment_mood_tags = []\n",
        "    words = comment.split(\" \")\n",
        "    total_word_count = len(words)\n",
        "    final_output = {\n",
        "        'sentics': {\n",
        "            'sensitivity': '0',\n",
        "            'attention': '0',\n",
        "            'pleasantness': '0',\n",
        "            'aptitude': '0',\n",
        "            'polarity': '0'\n",
        "        },\n",
        "        'mood tags': {}\n",
        "    }\n",
        "    for i in words:\n",
        "\n",
        "        try:\n",
        "            #word_emotion(i, sn)\n",
        "            polarity_intense += float(sn.polarity_intense(i))\n",
        "            #print sn.sentics(i)\n",
        "            sentics_values(i, sn, comment_sentics)\n",
        "            add_mood_tags(comment_mood_tags, sn, i)\n",
        "        except KeyError:\n",
        "            #print \"This word does not exist\", i\n",
        "            if (total_word_count > 1):\n",
        "                total_word_count -= 1\n",
        "            pass\n",
        "    comment_sentics_average(total_word_count, comment_sentics)\n",
        "    final_output['sentics']['polarity'] = polarity_intense / total_word_count\n",
        "    final_output['mood tags'] = comment_mood_tags\n",
        "    for output in final_output['sentics']:\n",
        "        if output in comment_sentics:\n",
        "            final_output['sentics'][output] = comment_sentics[output]\n",
        "\n",
        "    json_output = json.dumps(final_output)\n",
        "    print(json_output)\n",
        "    return json_output"
      ],
      "metadata": {
        "id": "Dj9zwYo5K5mg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from senticnet.senticnet import SenticNet\n",
        "from nltk.tokenize import word_tokenize\n",
        "import urllib\n",
        "\n",
        "def get_avg_polarity(message):\n",
        "    threshold = 0.3\n",
        "    #sn = Senticnet()\n",
        "    count = 0\n",
        "    summ = 0\n",
        "    #for word_options in get_words_bag(message):\n",
        "    for word_options in message:\n",
        "        polarity = 0\n",
        "        for word in word_options:\n",
        "            try:\n",
        "                concept = sn.concept(word)\n",
        "                polarity = concept['polarity']\n",
        "                break\n",
        "            #except urllib2.HTTPError:\n",
        "            except urllib.error.URLError:\n",
        "                pass  #Do next\n",
        "        if abs(polarity) > threshold:\n",
        "            summ += polarity\n",
        "            count += 1\n",
        "\n",
        "    return summ / count if count > 0 else 0\n",
        "\n",
        "get_avg_polarity('love like dream')"
      ],
      "metadata": {
        "id": "dvx8OkY9K5q1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_avg_polarity(message):\n",
        "  threshold = 0.3\n",
        "  sn = Senticnet()\n",
        "  count = 0\n",
        "  summ = 0\n",
        "  for word_options in get_words_bag(message):\n",
        "    polarity = 0\n",
        "    for word in word_options:\n",
        "      try:\n",
        "        concept = sn.concept(word)\n",
        "        polarity = concept['polarity']\n",
        "        break\n",
        "      except urllib2.HTTPError:\n",
        "        pass #Do next\n",
        "    if abs(polarity) > threshold:\n",
        "      summ += polarity\n",
        "      count += 1\n",
        "\n",
        "  return summ / count if count > 0 else 0"
      ],
      "metadata": {
        "id": "x1LPg4jzRUYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getInfo(self, concept):\n",
        "     try:\n",
        "         sn = Senticnet()\n",
        "         concept_info = sn.concept(concept)\n",
        "         polarity_value = sn.polarity_value(concept)\n",
        "         polarity_intense = sn.polarity_intense(concept)\n",
        "         moodtags = sn.moodtags(concept)\n",
        "         semantics = sn.semantics(concept)\n",
        "         sentics = sn.sentics(concept)\n",
        "         \"\"\"print(concept)\n",
        "         print(\"concept_info: {}\".format(concept_info))\n",
        "         print(\"polarity_value: {}\".format(polarity_value))\n",
        "         print(\"polarity_intense: {}\".format(polarity_intense))\n",
        "         print(\"moodtags: {}\".format(moodtags))\n",
        "         print(\"semantics: {}\".format(semantics))\n",
        "         print(\"sentics: {}\".format(sentics))\n",
        "         print(\"\\n\\n\")\"\"\"\n",
        "         return \"{} - {}\".format(polarity_value, polarity_intense)\n",
        "     except:\n",
        "         return \"NOT POSSIBLE\""
      ],
      "metadata": {
        "id": "J3UHrQZCRUhH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NkI3eT2aRapL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rVxsSlxwRaxD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}