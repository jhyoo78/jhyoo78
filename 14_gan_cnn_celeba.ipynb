{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNmVEd58qHGAhE+XFq07ftw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jhyoo78/jhyoo78/blob/main/14_gan_cnn_celeba.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CNN GAN - CelebA Human Faces"
      ],
      "metadata": {
        "id": "woo3mpdmN3N5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Asdr84l5e97Z"
      },
      "outputs": [],
      "source": [
        "# mount Drive to access data files\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('./mount')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "import h5py\n",
        "import pandas, numpy, random\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(torch.__version__)"
      ],
      "metadata": {
        "id": "eE38Y50we_Up"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 표준 CUDA 확인 및 설정"
      ],
      "metadata": {
        "id": "XS5Opg-hOFyB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# CUDA가 가용한지 검사한다 (즉, Jupyter의 런타임이 GPU로 설정되어 있어야 한다)==> 책 4장에서 설명하였음.\n",
        "# CUDA가 설치되어 있으면 default tensor type을 CUDA로 설정한다.\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
        "  print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
        "  pass\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "id": "_GvIlvoue_cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper 함수 정의"
      ],
      "metadata": {
        "id": "6BpfxxY3ObXz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# functions to generate random data\n",
        "\n",
        "def generate_random_image(size):\n",
        "    random_data = torch.rand(size)    # torch.rand() : 0과 1 사이의 숫자를 균등하게 size 크기의 tensor로 random하게  생성, 균등 분포\n",
        "    return random_data\n",
        "\n",
        "def generate_random_seed(size):\n",
        "    random_data = torch.randn(size)   # torch.randn() : 평균이 0이고 표준편차가 1인 가우시안 정규분포로 size 크기의 tensor를 random으로 생성\n",
        "    return random_data"
      ],
      "metadata": {
        "id": "PKe3WpIAOSFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# modified from https://github.com/pytorch/vision/issues/720\n",
        "\n",
        "class View(nn.Module):              # nn.Module을 부모 class로 하여 class를 선언하여 Sequential 내에서 사용하도록 하며,\n",
        "                                    # 3차원 텐서(218, 178, 3)를 1차원 텐서(218x178x3)으로 변환한다.\n",
        "    def __init__(self, shape):\n",
        "        super().__init__()\n",
        "        self.shape = shape,\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x.view(*self.shape)   # 매개변수 x에 전달하는 값(인자, argumnet)의 개수가 가변적일 때 *를 붙임"
      ],
      "metadata": {
        "id": "JvsxV857OSht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crop (numpy array) image to given width and height,\n",
        "# Numpy 이미지를 받아서 중앙을 기준으로 128x128 이미지를 추출함\n",
        "\n",
        "def crop_centre(img, new_width, new_height):\n",
        "    height, width, _ = img.shape             #img.shape는 height, width, channel(BGR)을 출력함\n",
        "    startx = width//2 - new_width//2\n",
        "    starty = height//2 - new_height//2\n",
        "    return img[ starty:starty + new_height, startx:startx + new_width, :]   # starty부터 new_height 까지 x startx부터 new_width까지 이미지를 리턴, : 은 전체를 의미"
      ],
      "metadata": {
        "id": "zqcIBvlNOStb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from matplotlib import image\n",
        "# dataset class\n",
        "\n",
        "class CelebADataset(Dataset):\n",
        "\n",
        "    def __init__(self, file):\n",
        "        self.file_object = h5py.File(file, 'r')     # HDF5 file을 read로 연다.\n",
        "        self.dataset = self.file_object['img_align_celeba']  #  group이 img_align_celeba 인 그룹을 dataset에 저장한다.\n",
        "        pass\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)                    # dataset의 개수를 리턴,\n",
        "\n",
        "    def __getitem__(self, index):                   # __getitem__은 클래스의 인덱스에 접근할 때 자동으로 호출되는 magic method이다.\n",
        "        if (index >= len(self.dataset)):                    # index가 데이터 수보다 큰 경우 오류가 발생하므로 이를 예외로 처리하도록 한다.\n",
        "          raise IndexError()\n",
        "        img = numpy.array(self.dataset[str(index)+'.jpg'])  # index를 jpg 파일의 이름으로하여 numpy 행렬로 변환한다.\n",
        "        return torch.cuda.FloatTensor(img).permute(2,0,1).view(1,3,128,128) / 255.0         # 코드 12 에서 변경됨 -- 이미지의 텐서를 CUDA 텐서로 리턴한다.\n",
        "\n",
        "    def plot_image(self, index):                             # 코드 12 에서 변경됨 -- 이미지 crop_center() 사용함\n",
        "        img = numpy.array(self.dataset[str(index)+'.jpg'])\n",
        "        # crop to 128x128 square\n",
        "        img = crop_centre(img, 128, 128)\n",
        "        plt.imshow(img, interpolation='nearest')\n",
        "        pass\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "MnfQ0nYue_f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create Dataset object\n",
        "\n",
        "celeba_dataset = CelebADataset('mount/My Drive/Colab Notebooks/myo_gan/celeba/celeba_aligned_small.h5py')"
      ],
      "metadata": {
        "id": "0TtI7Xnhe_jI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check data contains images\n",
        "\n",
        "celeba_dataset.plot_image(41)"
      ],
      "metadata": {
        "id": "pv3rsnrce_mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Discriminator Network"
      ],
      "metadata": {
        "id": "YY9hGec1Q-Nt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# discriminator class\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        # initialise parent pytorch class\n",
        "        super().__init__()\n",
        "\n",
        "        # define neural network layers\n",
        "        self.model = nn.Sequential(\n",
        "            # expect input of shape (1,3,128,128)\n",
        "            nn.Conv2d(3, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.Conv2d(256, 3, kernel_size=8, stride=2),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            View(3*10*10),\n",
        "            nn.Linear(3*10*10, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # create loss function\n",
        "        self.loss_function = nn.BCELoss()\n",
        "\n",
        "        # create optimiser, simple stochastic gradient descent\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        # counter and accumulator for progress\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # simply run model\n",
        "        return self.model(inputs)\n",
        "\n",
        "\n",
        "    def train(self, inputs, targets):\n",
        "        # calculate the output of the network\n",
        "        outputs = self.forward(inputs)\n",
        "\n",
        "        # calculate loss\n",
        "        loss = self.loss_function(outputs, targets)\n",
        "\n",
        "        # increase counter and accumulate error every 10\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "        if (self.counter % 1000 == 0):\n",
        "            print(\"counter = \", self.counter)\n",
        "            pass\n",
        "\n",
        "        # zero gradients, perform a backward pass, update weights\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def plot_progress(self):\n",
        "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "S_CAiXdke_uy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test Discriminator  \n",
        "코드에서 오류 발생 시, Pytorch를 12.0.1 이상으로 upgrade해야 함.\n",
        "임시방편으로 Adam optimizer를 SGD로 환원시킴"
      ],
      "metadata": {
        "id": "JJlk_-II48LI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "# test discriminator can separate real data from random noise\n",
        "\n",
        "D = Discriminator()\n",
        "# move model to cuda device\n",
        "D.to(device)\n",
        "\n",
        "for image_data_tensor in celeba_dataset:\n",
        "    # real data\n",
        "    D.train(image_data_tensor, torch.cuda.FloatTensor([1.0]))\n",
        "    # fake data\n",
        "    D.train(generate_random_image((1,3,128,128)), torch.cuda.FloatTensor([0.0]))\n",
        "    pass\n",
        "\n",
        " # counter=40000에서 종료됨"
      ],
      "metadata": {
        "id": "nmmPYg0BfQbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot discriminator loss\n",
        "\n",
        "D.plot_progress()"
      ],
      "metadata": {
        "id": "Zg9J4tevfQrh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# D를 수동 구동하여 실제와 가짜 데이터를 구별하는지 확인해 보자.\n",
        "\n",
        "for i in range(4):\n",
        "  image_data_tensor = celeba_dataset[random.randint(0,20000)]\n",
        "  print( D.forward( image_data_tensor ).item() )\n",
        "  pass\n",
        "\n",
        "for i in range(4):\n",
        "  print( D.forward( generate_random_image((1,3,128,128))).item() )\n",
        "  pass"
      ],
      "metadata": {
        "id": "tsT8Ap1qfQ00"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generator Network"
      ],
      "metadata": {
        "id": "wtvS6JfeRv3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator 클래스\n",
        "\n",
        "class Generator(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        # initialise parent pytorch class\n",
        "        super().__init__()\n",
        "\n",
        "        # define neural network layers\n",
        "        self.model = nn.Sequential(\n",
        "            # input is a 1d array\n",
        "            nn.Linear(100, 3*11*11),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            # reshape to 4d\n",
        "            View((1, 3, 11, 11)),\n",
        "\n",
        "            nn.ConvTranspose2d(3, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 256, kernel_size=8, stride=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.LeakyReLU(0.2),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 3, kernel_size=8, stride=2, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "\n",
        "            # output should be (1,3,128,128)\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "        # create optimiser, simple stochastic gradient descent\n",
        "        self.optimiser = torch.optim.Adam(self.parameters(), lr=0.0001)\n",
        "\n",
        "        # counter and accumulator for progress\n",
        "        self.counter = 0;\n",
        "        self.progress = []\n",
        "\n",
        "        pass\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        # simply run model\n",
        "        return self.model(inputs)\n",
        "\n",
        "\n",
        "    def train(self, D, inputs, targets):\n",
        "        # calculate the output of the network\n",
        "        g_output = self.forward(inputs)\n",
        "\n",
        "        # Discriminator에게 전달하여 처리하도록 한다.\n",
        "        d_output = D.forward(g_output)\n",
        "\n",
        "        # 손실을 계산한다.\n",
        "        loss = D.loss_function(d_output, targets)\n",
        "\n",
        "        # increase counter and accumulate error every 10\n",
        "        self.counter += 1;\n",
        "        if (self.counter % 10 == 0):\n",
        "            self.progress.append(loss.item())\n",
        "            pass\n",
        "\n",
        "        # zero gradients, perform a backward pass, update weights\n",
        "        self.optimiser.zero_grad()\n",
        "        loss.backward()\n",
        "        self.optimiser.step()\n",
        "\n",
        "        pass\n",
        "\n",
        "\n",
        "    def plot_progress(self):\n",
        "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
        "        df.plot(ylim=(0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5, 1.0, 5.0))\n",
        "        pass\n",
        "\n",
        "    pass"
      ],
      "metadata": {
        "id": "ixu3mrDmfXPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test Generator Output"
      ],
      "metadata": {
        "id": "8wYO4bpTSK0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# G의 출력이 올바른 type과 shape를 가지고 있는지 확인한다.\n",
        "\n",
        "G = Generator()\n",
        "# move model to cuda device\n",
        "G.to(device)\n",
        "\n",
        "output = G.forward(generate_random_seed(100))    # G의 self.model의 입력에 맞추어 100으로 설정함\n",
        "\n",
        "img = output.detach().permute(0,2,3,1).view(128,128,3).cpu().numpy()\n",
        "\n",
        "plt.imshow(img, interpolation='none', cmap='Blues')   # 훈련되지 않은 G의 출력은 임의의 데이터 패턴을 만듬. 어떤 패턴이 보이면 코드 오류로 봐야 함,"
      ],
      "metadata": {
        "id": "kTBGgltFfXYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train GAN"
      ],
      "metadata": {
        "id": "JUZcqMNsSbOy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "\n",
        "# create Discriminator and Generator\n",
        "\n",
        "D = Discriminator()\n",
        "D.to(device)\n",
        "G = Generator()\n",
        "G.to(device)\n",
        "\n",
        "epochs = 1\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  print (\"epoch = \", epoch + 1)\n",
        "\n",
        "  # train Discriminator and Generator\n",
        "\n",
        "  for image_data_tensor in celeba_dataset:\n",
        "    # D를 True에 대해 훈련시킨다.\n",
        "    D.train(image_data_tensor, torch.cuda.FloatTensor([1.0]))\n",
        "\n",
        "    # D를 False에 대해 훈련시킨다.\n",
        "    D.train(G.forward(generate_random_seed(100)).detach(), torch.cuda.FloatTensor([0.0]))\n",
        "\n",
        "    # G를 훈련시킨다.\n",
        "    G.train(D, generate_random_seed(100), torch.cuda.FloatTensor([1.0]))\n",
        "\n",
        "    pass\n",
        "\n",
        "  pass\n",
        "\n",
        "  # epoch=1일 때 counter=40000에서 종료됨"
      ],
      "metadata": {
        "id": "7ZfWQ3EkfYOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot discriminator error\n",
        "\n",
        "D.plot_progress()"
      ],
      "metadata": {
        "id": "4vUkbeh5fYXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot generator error\n",
        "\n",
        "G.plot_progress()"
      ],
      "metadata": {
        "id": "feeOeidDfgdJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run Generator"
      ],
      "metadata": {
        "id": "eZu_W1vIS5JB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot several outputs from the trained generator\n",
        "\n",
        "# plot a 3 column, 2 row array of generated images\n",
        "f, axarr = plt.subplots(2,3, figsize=(16,8))\n",
        "for i in range(2):\n",
        "    for j in range(3):\n",
        "        output = G.forward(generate_random_seed(100))\n",
        "        img = output.detach().permute(0,2,3,1).view(128,128,3).cpu().numpy()\n",
        "        axarr[i,j].imshow(img, interpolation='none', cmap='Blues')\n",
        "        pass\n",
        "    pass"
      ],
      "metadata": {
        "id": "SUGyw4PffgmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# current memory allocated to tensors (in Gb)\n",
        "\n",
        "torch.cuda.memory_allocated(device) / (1024*1024*1024)"
      ],
      "metadata": {
        "id": "5CI9oU0XflTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# total memory allocated to tensors during program (in Gb)\n",
        "\n",
        "torch.cuda.max_memory_allocated(device) / (1024*1024*1024)"
      ],
      "metadata": {
        "id": "rqoJY93qfmAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# summary of memory consumption\n",
        "\n",
        "print(torch.cuda.memory_summary(device, abbreviated=True))"
      ],
      "metadata": {
        "id": "KG22EHJcfmUI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}